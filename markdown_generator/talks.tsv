title	type	url_slug	venue	date	location	talk_url	description
Issue Topic based Argumentative Structure Extraction from Japanese Judgment Documents	Presentation	talk-1	"National Institute of Informatics (NII), Informal Workshop on Argumentation/Argument Mining"	2018/11/14	"Tokyo, Japan"	http://research.nii.ac.jp/~ksatoh/ArgWS2018.html	
Argument structure-based summarization of Japanese judgment documents	Presentation	talk-2	Legal Data Mining Conference	2019/3/21	"Paris, France"	https://legaldatamining.com/	
テクノロジーとリーガルイノベーション(ゲスト講師)	Talk	talk-3	一橋大学	2022/1/18	"Tokyo, Japan"	https://syllabus.cels.hit-u.ac.jp/hit_syllabus/2021/05/05_1JJ71801_ja_JP.html	
日本語判決書を用いたデータセットの構築	Presentation	talk-4	NLP2022 Workshop on Japanese Evaluation Dataset (JED2022)	2022/3/18	"Hamamatsu, Japan"	https://jedworkshop.github.io/jed2022/program/#%E3%83%AA%E3%83%BC%E3%82%AC%E3%83%AB%E5%88%86%E9%87%8E%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E6%A7%8B%E7%AF%89%E3%83%BB%E5%88%A9%E6%B4%BB%E7%94%A8%E3%81%AE%E7%8F%BE%E7%8A%B6%E3%81%A8%E5%B1%95%E6%9C%9B	"近年、法律ドメインにおいても自然言語処理研究が活発になりつつあるが、海外では判決書を元に作成されたデータセットが容易に入手可能な状況となっている一方で、日本語で書かれた日本法に対応するデータセットの普及は進んでいない。日本の言語及び法制度の特徴が反映されたデータに基づいて既存手法を検証するため、そして新規手法の研究開発を促進するためにも、日本語・日本法に基づくデータセットの整備・共有は急務である。本発表では、過去に構築した日本語判決書議論マイニングデータセットおよび、現在構築中の日本語判決書判断予測データセットについて、各データセットの概要とその構築の過程を紹介する。特に、法律ドメインにおけるアノテーションに関して、作業者の選定から、アノテーションスキームの開発・専門家を動員したアノテーションの運用とその課題まで、実際のデータセット構築を通して得られた知見について共有する。"
『リーガルイノベーション入門』(パネル)	Invited Talk	talk-5	一橋大学GGRウェビナー	2022/10/14	"Tokyo, Japan"	https://www.koubundou.co.jp/news/n49107.html	
Designing automated feedback on source text content representation in a web-based formative assessment module for L2 summary writing 	Presentation	talk-6	44th Language Testing Research Colloquium (LTRC)	2023/6/8	"New York, USA"	https://ltrc2023.weebly.com/	""
Japanese Tort-case Dataset for Rationale-supported Legal Judgment Prediction  	Invited Talk	talk-7	“Legal Systems and Artificial Intelligence” Final Event	2023/12/19	"Tokyo, Japan"	https://legalinnovation.hias.hit-u.ac.jp/en/event/symposium20231218/	""
LLMを活用した英作文自動フィードバック の検討   	Talk	talk-8	第56回言語テスト学会研究例会	2024/3/9	Online	https://jlta2016.sakura.ne.jp/?p=1995	""
The Role of Prompt Engineering in Ensuring the Consistency Between Instructor and LLM Checklist Ratings on Written Summary Content 	Presentation	talk-9	46th Language Testing Research Colloquium (LTRC)	2025/6/7	"Bangkok, Thailand"	https://www.culi.chula.ac.th/2025LTRC/index.html	"The rapidly-growing large language model (LLM) applications to L2 instruction and assessment in recent years informs explorations of options for timely provision of fine-grained feedback on traditionally underexplored, complex task types such as summary writing. Yet, key validity issues such as the consistency between LLM ratings and instructor ratings and effects of different prompts for automated scoring and feedback on the consistency require careful examination. The present study addressed exactly these issues, specifically focusing on checklist-based rating on main idea representation in written summaries (Kintsch & van Dijk, 1978; van Dijk & Kintsch, 1983). Ninety-seven summaries written in English by undergraduates in Japan were analyzed. Two writing course instructors rated all summaries with partial double rating. We then developed six prompts by manipulating two features: the amount of information included (three types including few-shot); and the order in which rating and its explanation were generated in the LLM output (two types). By employing OpenAI GPT- 4 turbo through Open AI API, we examined the instructor vs. LLM rating consistency based on agreement indices and confusion matrices. Results showed satisfactory levels of agreement for low-stakes purposes for certain prompt type-by-item combinations, with a notable effect of the amount of information included in the prompt. LLM ratings were also found to be generally harsher than human ratings. Key results will be discussed along with qualitative analysis results of the LLM output as well as study implications for LLM analysis of checklists and their applications to granular feedback provision. "
Argument Annotation in Japanese Employment Law Cases: Preliminary Results 	Presentation	talk-10	The 12th Workshop on Argument Mining	2025/7/31	"Vienna, Austria"	https://argmining-org.github.io/2025/index.html	"We aim to develop an automated annotation system of Japanese legal argumentation in judgments for faster and reliable legal research and analysis. As a first step, we present our annotation task concerning fine-grained factors of legal reasoning and report a preliminary result of manual annotation on the Japanese judgments of employment contract cases." 